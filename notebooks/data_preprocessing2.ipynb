{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_lines = []\n",
    "\n",
    "with open(\"../data/full_dataset-release.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i].strip()\n",
    "\n",
    "    if line and line[0].isdigit() and i + 1 < len(lines):\n",
    "        next_line = lines[i + 1].strip()\n",
    "\n",
    "        if next_line.startswith(\",\"):\n",
    "            combined = line + next_line\n",
    "            fixed_lines.append(combined)\n",
    "            i += 2\n",
    "            continue\n",
    "\n",
    "    fixed_lines.append(line)\n",
    "    i += 1\n",
    "\n",
    "with open(\"../data/fixed_dataset.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in fixed_lines:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/gj667hr12xq0lkb3bn4rjxkc0000gp/T/ipykernel_34925/1296824117.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/fixed_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/fixed_dataset.csv')\n",
    "\n",
    "df.columns = [\n",
    "    'id', 'text', 'ticker', 'date', 'price',\n",
    "    'return_1d', 'return_2d', 'return_3d', 'return_7d',\n",
    "    'volume', 'volatility_10d', 'volatility_30d',\n",
    "    'lstm_sentiment', 'textblob_sentiment'\n",
    "]\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "df = df.drop(columns=['id', 'volatility_10d', 'volatility_30d', 'lstm_sentiment', 'textblob_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>return_2d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>return_7d</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @robertoglezcano: @amazon  #Patents Show Fl...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>823.48</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>3137196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@FAME95FM1 Jamaicans make money with @Payoneer...</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>39.78</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>9100057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CBSi Jamaicans make money with @Payoneer @Pay...</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>39.78</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>9100057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Hitz92fm Jamaicans make money with @Payoneer ...</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>39.78</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>9100057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @loadsofvans: Retweet this post &amp;amp; follo...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>823.48</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>3137196.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ticker       date  \\\n",
       "0  RT @robertoglezcano: @amazon  #Patents Show Fl...  Amazon 2017-01-31   \n",
       "1  @FAME95FM1 Jamaicans make money with @Payoneer...  PayPal 2017-01-31   \n",
       "2  @CBSi Jamaicans make money with @Payoneer @Pay...  PayPal 2017-01-31   \n",
       "3  @Hitz92fm Jamaicans make money with @Payoneer ...  PayPal 2017-01-31   \n",
       "4  RT @loadsofvans: Retweet this post &amp; follo...  Amazon 2017-01-31   \n",
       "\n",
       "    price  return_1d  return_2d  return_3d  return_7d     volume  \n",
       "0  823.48   0.008379   0.014924   0.014924  -0.001263  3137196.0  \n",
       "1   39.78   0.002011   0.012318   0.012318   0.054801  9100057.0  \n",
       "2   39.78   0.002011   0.012318   0.012318   0.054801  9100057.0  \n",
       "3   39.78   0.002011   0.012318   0.012318   0.054801  9100057.0  \n",
       "4  823.48   0.008379   0.014924   0.014924  -0.001263  3137196.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "chunk_size = 50000\n",
    "num_chunks = 7\n",
    "\n",
    "chunks = [df[i * chunk_size : (i + 1) * chunk_size] for i in range(num_chunks)]\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.to_csv(f\"./data/df_chunk_{i+1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"../models/finbert-finetuned1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/finbert-finetuned1\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Chunk 1: 100%|██████████| 782/782 [59:29<00:00,  4.56s/it]  \n",
      "Classifying Chunk 2: 100%|██████████| 782/782 [1:07:18<00:00,  5.16s/it]\n",
      "Classifying Chunk 3: 100%|██████████| 782/782 [1:05:28<00:00,  5.02s/it]\n",
      "Classifying Chunk 4: 100%|██████████| 782/782 [51:01<00:00,  3.92s/it]  \n",
      "Classifying Chunk 5: 100%|██████████| 782/782 [52:12<00:00,  4.01s/it]    \n",
      "Classifying Chunk 6: 100%|██████████| 782/782 [48:57<00:00,  3.76s/it]\n",
      "Classifying Chunk 7: 100%|██████████| 782/782 [1:28:30<00:00,  6.79s/it]    \n"
     ]
    }
   ],
   "source": [
    "chunk_paths = [f\"./data/df_chunk_{i}.csv\" for i in range(1, 8)]\n",
    "\n",
    "for i, path in enumerate(chunk_paths):\n",
    "    df = pd.read_csv(path)\n",
    "    texts = df['text'].tolist()\n",
    "\n",
    "    batch_size = 64\n",
    "    preds, probs = [], []\n",
    "\n",
    "    for j in tqdm(range(0, len(texts), batch_size), desc=f\"Classifying Chunk {i+1}\"):\n",
    "        batch_texts = texts[j:j + batch_size]\n",
    "        enc = tokenizer(batch_texts, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(**enc).logits\n",
    "            batch_probs = softmax(logits, dim=1)\n",
    "            preds.extend(batch_probs.argmax(dim=1).cpu().tolist())\n",
    "            probs.extend(batch_probs.cpu().tolist())\n",
    "            \n",
    "    df['sentiment_label'] = preds\n",
    "    df['positive'] = [p[0] for p in probs]\n",
    "    df['neutral'] = [p[1] for p in probs]\n",
    "    df['negative'] = [p[2] for p in probs]\n",
    "\n",
    "    df.to_csv(f\"./data/df_chunk_{i+1}_with_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_chunks = pd.concat(\n",
    "    [pd.read_csv(f) for f in sorted(glob.glob(\"./data/df_chunk_*_with_sentiment.csv\"))],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = all_chunks.groupby(['ticker', 'date']).agg({\n",
    "    'text': lambda x: list(x),\n",
    "    'sentiment_label': lambda x: list(x),\n",
    "    'positive': lambda x: list(x),\n",
    "    'neutral': lambda x: list(x),\n",
    "    'negative': lambda x: list(x),\n",
    "    'return_1d': lambda x: list(x),\n",
    "    'return_2d': lambda x: list(x),\n",
    "    'return_3d': lambda x: list(x)\n",
    "}).reset_index()\n",
    "\n",
    "daily_sentiment = all_chunks.groupby([\"ticker\", \"date\"]).agg({\n",
    "    \"positive\": \"mean\",\n",
    "    \"neutral\": \"mean\",\n",
    "    \"negative\": \"mean\",\n",
    "    \"return_1d\": \"first\",\n",
    "    \"return_2d\": \"first\",\n",
    "    \"return_3d\": \"first\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment = daily_sentiment.dropna(subset=['positive', 'neutral', 'negative', 'return_1d'])\n",
    "daily_sentiment = daily_sentiment.sort_values(by=['ticker', 'date'])\n",
    "daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>return_2d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>ticker_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>21CF</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.002868</td>\n",
       "      <td>-0.002868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>21CF</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>21CF</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>21CF</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-02-04</td>\n",
       "      <td>21CF</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker  positive   neutral  negative  return_1d  return_2d  \\\n",
       "0 2017-01-31   21CF  0.000167  0.999619  0.000214  -0.000319  -0.002868   \n",
       "1 2017-02-01   21CF  0.000000  0.000000  0.000000        NaN        NaN   \n",
       "2 2017-02-02   21CF  0.000000  0.000000  0.000000        NaN        NaN   \n",
       "3 2017-02-03   21CF  0.000000  0.000000  0.000000        NaN        NaN   \n",
       "4 2017-02-04   21CF  0.000000  0.000000  0.000000        NaN        NaN   \n",
       "\n",
       "   return_3d  ticker_encoded  \n",
       "0  -0.002868               0  \n",
       "1        NaN               0  \n",
       "2        NaN               0  \n",
       "3        NaN               0  \n",
       "4        NaN               0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fill in missing dates per ticker\n",
    "\n",
    "filled_df = []\n",
    "\n",
    "for ticker, group in daily_sentiment.groupby('ticker'):\n",
    "    group = group.sort_values('date').reset_index(drop = True)\n",
    "    index = pd.date_range(start = group['date'].min(), \n",
    "                          end = group['date'].max(),\n",
    "                          freq = 'D')\n",
    "    group = group.set_index('date').reindex(index).reset_index()\n",
    "    group['ticker'] = ticker\n",
    "    group.rename(columns = {'index': 'date'}, inplace = True)\n",
    "    filled_df.append(group)\n",
    "    \n",
    "df_full = pd.concat(filled_df, ignore_index=True)\n",
    "\n",
    "for col in ['positive', 'neutral', 'negative']:\n",
    "    df_full[col] = df_full[col].fillna(0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_full['ticker_encoded'] = le.fit_transform(df_full['ticker'])\n",
    "    \n",
    "df_full = df_full.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_csv(\"../data/full_sentiment_dataset.csv\", index=False)\n",
    "df_full.to_csv(\"../data/full_sentiment_dataset_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FinBERT Global)",
   "language": "python",
   "name": "finbert-global"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
